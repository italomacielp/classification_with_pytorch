# üíª Projetos de Sistemas baseados em Aprendizado de M√°quina 

## Projeto 2: Visualiza√ß√£o das Camadas da CNN: Um Estudo de Caso
<p align="center">
  <a href="#">
    <img src="results/modelo_lenet.png" alt="Logo" width="800" height="300">
  </a>
</p>

### üèÉ Componentes
1. Paula Souza
2. √çtalo Maciel

### üìå Descri√ß√£o do projeto
<p align="justify">
O Trabalho da Unidade 02 √© um Estudo de Caso que visa a Visualiza√ß√£o das Camadas da CNN (Rede Neural Convolucional).
</p>
<p align="justify">
O projeto exige a manipula√ß√£o de componentes espec√≠ficos, mantendo a arquitetura-base (LeNet-like) como visto em aula, adaptando apenas in_channels se necess√°rio.
</p>
<p align="justify">
A tarefa principal √© aplicar a predi√ß√£o da arquitetura da CNN sobre essas imagens,culminando na visualiza√ß√£o gr√°fica de imagens e seus r√≥tulos correspondentes.
</p>
<p align="justify">
O estudo est√° inserido no contexto da explora√ß√£o de CNNs com PyTorch e deve ser entregue at√© o dia 23 de novembro de 2025 (23h59).
</p>

### ‚ñ∂Ô∏è Instru√ß√µes para executar o c√≥digo
<p align="justify">

1. Clone o reposit√≥rio utilizando o seguinte comando git na sua m√°quina.

``` git clone https://github.com/italomacielp/classification_with_pytorch```

2. Realize o upload no colab notebook. Acessando o menu do colab e seguir o seguinte fluxo: <u>Arquivo ‚Üí Fazer Upload de Arquivo.</u>

3. Execute todas as c√©lulas com a op√ß√£o: *Executar tudo*.
</p>

### üöß Arquitetura
<p align="justify">
A classe Architecture serve como um cont√™iner completo para treinamento, valida√ß√£o, an√°lise e visualiza√ß√£o de modelos em PyTorch. 
</p>
<p align="justify">
Ela recebe o modelo, a fun√ß√£o de perda e o otimizador, configurando automaticamente o dispositivo (CPU/GPU) e gerenciando loaders de treino e valida√ß√£o. A classe cria fun√ß√µes internas de train step e validation step, que executam o forward, calculam a perda, fazem o backward e atualizam os pesos quando necess√°rio, tamb√©m controla todo o loop de treinamento, armazenando perdas, √©pocas e permitindo salvar e carregar checkpoints. 
</p>
<p align="justify">
Al√©m disso, oferece m√©todos para prever novos dados, contar par√¢metros, visualizar filtros de camadas convolucionais, registrar hooks para capturar ativa√ß√µes internas e plotar curvas de perda. Por fim, inclui fun√ß√µes utilit√°rias como defini√ß√£o de semente, avalia√ß√£o de acur√°cia por classe e aplica√ß√£o de opera√ß√µes ao longo dos loaders.
</p>

### üìÅ  Base de Dados
<p align="justify">
Nesse trabalho estamos analisando o conjunto de dados MNIST. Esse banco de imagens √© um dos mais utilizados em estudos e experimentos envolvendo reconhecimento de padr√µes, 
servindo como uma base ideal para observar o desempenho de modelos de vis√£o computacional em tarefas simples de classifica√ß√£o.
</p>
<p align="justify">
O MNIST re√∫ne 60.000 imagens em tons de cinza cada uma com resolu√ß√£o 28√ó28 pixels, contendo registros de d√≠gitos manuscritos.
</p>
<p align="justify">
Esses exemplos est√£o organizados em 10 categorias, representando os n√∫meros de 0 a 9. 
Essa estrutura compacta e padronizada facilita a compreens√£o dos primeiros passos na constru√ß√£o e treinamento de modelos convolucionais.
</p>

### üöã Estrutura da arquitetura base (Modelo LeNet-like)
<p align="justify">
A arquitetura segue uma estrutura padr√£o do modelo LeNet contendo blocos de *featurizer* e *classifier*, que correspondem captura de atributos e classifica√ß√£o dos dados. Os blocos contidos na camada de captura de atributos √© constituida por:
</p>

- Entrada (Input): Recebe a imagem em sua dimensionalidade real e distribui os pixels para a rede neural, nesse caso foi utilizada a base de dados MNIST que possui imagens 28x28 e somente 1 canal. 
- Convolu√ß√µes (Conv2D): Tem como fun√ß√£o extrair caracter√≠sticas importantes da imagem, a partir da aplica√ß√£o de filtros (kernels) na imagem. Cada filtro pode detectar padr√µes, como:
1. Bordas
2. Texturas
3. Curvas
4. Tra√ßos
- Redu√ß√£o de dimensionalidade (Pooling): Reduz o mapa de caracter√≠sticas, com objetivo de resumir a imagem mantendo as informa√ß√µes mais importantes dela para o processo de classifica√ß√£o, servindo tamb√©m para evitar *overfitting*.
- Achatamento (Flatten): Achata as sa√≠das 2D para um vetor 1D, importante para encarregar esses dados nas camadas profundas.
Os blocos contidos na camada de classifica√ß√£o √© constituida por:
- Camada densa (FC): Que realiza a combina√ß√£o das caracter√≠sticas detectadas, e aprende as rela√ß√µes complexas entre as caracter√≠sticas.
- Sa√≠da: Possui uma classe por neur√¥nio de sa√≠da, convertendo os valores em probabilidades. Com o objetivo geral de decis√£o de qual classe a imagem pertence.

<p align="justify">

**Observa√ß√£o**: Foram adicionadas camadas de *dropout* antes da sa√≠da. Esse tipo de camada √© √∫til reduzir o overfitting, desligando neur√¥nios durante o treinamento realizando uma distribui√ß√£o melhor dos dados.
</p>

### üìä Explica√ß√£o dos seus resultados e observa√ß√µes
#### Curvas de treinamento e valida√ß√£o
<p align="center">
  <a href="#">
    <img src="results/curvas_treinamento_validacao_1.png" alt="Logo" width="500" height="500">
  </a>
</p>

<p align="justify">
Com base na curva apresentada para o modelo sem ajustes e configurado para 20 √©pocas de treinamento, observa-se um comportamento de overfitting. Isso indica que o modelo passa a memorizar os dados de treinamento, reduzindo sua capacidade de generaliza√ß√£o e prejudicando o desempenho nas predi√ß√µes sobre novos dados.
</p>

<p align="center">
  <a href="#">
    <img src="results/curvas_treinamento_validacao_2.png" alt="Logo" width="500" height="500">
  </a>
</p>

<p align="justify">
Com a aplica√ß√£o da camada de dropout, observa-se uma melhora significativa na aproxima√ß√£o entre as curvas de treinamento e valida√ß√£o, mantendo a mesma quantidade de √©pocas. Nesse caso, foi utilizado um dropout de 50%, o que significa que metade dos neur√¥nios √© desativada aleatoriamente durante o treinamento, reduzindo o risco de overfitting. Ainda assim, √© poss√≠vel aprimorar o modelo com ajustes adicionais.
</p>

<p align="center">
  <a href="#">
    <img src="results/curvas_treinamento_validacao_3.png" alt="Logo" width="500" height="500">
  </a>
</p>

<p align="justify">
Na √∫ltima curva, aumentou-se a quantidade de √©pocas e reduziu-se a taxa de dropout utilizada na camada oculta. Mesmo com essas altera√ß√µes, o modelo manteve um bom desempenho, mostrando curvas de treinamento e valida√ß√£o mais pr√≥ximas. Com um n√∫mero maior de √©pocas, a tend√™ncia de aproxima√ß√£o se torna mais evidente, indicando um comportamento mais est√°vel e consistente do modelo.
</p>

#### Matriz de confus√£o
<p align="center">
  <a href="#">
    <img src="results/matriz_confusao.png" alt="Logo" width="500" height="500">
  </a>
</p>

<p align="justify">
Pela matriz de confus√£o apresentada, observa-se que o modelo apresenta um desempenho considerado excelente. Isso ocorre porque a maior parte das previs√µes corretas se concentra na diagonal principal, indicando alta taxa de acerto ao identificar corretamente cada classe.
</p>

#### Mapa de caracter√≠sticas

<p align="center">
  <a href="#">
    <img src="results/features.png" alt="Logo" width="800" height="1000">
  </a>
</p>

<p align="justify">
O mapa de caracter√≠sticas apresentado permite visualizar e depurar as transforma√ß√µes que a imagem de entrada sofre nas camadas subsequentes, evidenciando quais padr√µes s√£o extra√≠dos e quais regi√µes se tornam mais relevantes para o modelo.
</p>

### üé• Link para o v√≠deo da sua apresenta√ß√£o
![LINK DA APRESENTA√á√ÉO]()

### ‚úÖ Checklist de Entrega

| Item | Descri√ß√£o | Status |
|------|--------------|--------|
| Dataset | Escolher um dataset do torchvision.datasets | ‚úÖ |
| Arquitetura | Manter a arquitetura-base (LeNet-like) como visto em aula, adaptando apenas in_channels se necess√°rio. | ‚úÖ|
| Loss Functions/M√©tricas | Treinar o modelo e registrar m√©tricas de loss e accuracy (treino/val) | ‚úÖ |
| Hooks | Implementar Hooks para capturar ativa√ß√µes intermedi√°rias. | ‚úÖ |
| Visualiza√ß√£o | Visualizar os feature maps de todas camadas. | ‚úÖ |
| An√°lise | Escrever uma breve an√°lise (1-2 par√°grafos) sobre o que foi observado. | ‚úÖ |
| Video | Gravar um v√≠deo de at√© 10min sobre o que foi observado. | ‚òê |
| Reposit√≥rio | Organizar um reposit√≥rio no Github com tudo o que foi desenvolvido, incluindo um arquivo README.md descrevendo todo trabalho em detalhes. | ‚úÖ |
---